---
- name: Create Infrastructure
  hosts: localhost
  tasks:
    - name: Create VPC, Subnets, NAT Gateways, Route Tables, Security Groups and Route53 Zones
      include_role:
        name: aws-customer-infrastructure
      vars:
        aws_customer_vpc_cidr: "{{ vpc_cidr }}"
        aws_customer_vpc_env_name: "{{ vpc_env_name }}"
        aws_customer_vpc_region: "{{ vpc_region }}"
        publicaz1_cidr: "{{ pubaz1_cidr }}"
        publicaz2_cidr: "{{ pubaz2_cidr }}"
        publicaz3_cidr: "{{ pubaz3_cidr }}"
        managementaz1_cidr: "{{ manaz1_cidr }}"
        managementaz2_cidr: "{{ manaz2_cidr }}"
        managementaz3_cidr: "{{ manaz3_cidr }}"
        customeraz1_cidr: "{{ custaz1_cidr }}"
        customeraz2_cidr: "{{ custaz2_cidr }}"
        customeraz3_cidr: "{{ custaz3_cidr }}"
        clusteraz1_cidr: "{{ clustaz1_cidr }}"
        clusteraz2_cidr: "{{ clustaz2_cidr }}"
        clusteraz3_cidr: "{{ clustaz3_cidr }}"
        aws_customer_vpc_management_cidr: "{{ vpc_management_cidr }}"
        aws_customer_vpc_shortname: "{{ vpc_shortname }}"
        aws_customer_vpc_longname: "{{ vpc_longname }}"
        create_zone: true
        single_az: "{{ single_availability_zone }}"
    - name: Set VPC ID for DR Peering
      set_fact:
        vpcid: "{{ customer_network.vpc.id }}"
      when: dr_compartment
    - name: Set Management AZ1 Route Table ID for DR Peering
      set_fact:
        manaz1rt: "{{ managementaz1_route_table.route_table.route_table_id }}"
      when: dr_compartment
    - name: Set Management AZ2 Route Table ID for DR Peering
      set_fact:
        manaz2rt: "{{ managementaz2_route_table.route_table.route_table_id }}"
      when: dr_compartment and not dr_single_availability_zone
    - name: Set Management AZ3 Route Table ID for DR Peering
      set_fact:
        manaz3rt: "{{ managementaz3_route_table.route_table.route_table_id }}"
      when: dr_compartment and not dr_single_availability_zone
    - name: Set Reverse Zone for DR
      set_fact:
        rev_zone: "{{ reverse_zone.zone_id }}"
      when: dr_compartment

- name: Provision Component Machines
  hosts: localhost
  tasks:
    - name: Provision FDE ec2 VM
      include_role:
        name: aws-ec2-vm
      vars:
        aws_ec2_vm_Name: FDE
        aws_ec2_vm_region: "{{ vpc_region }}"
        aws_ec2_vm_key_name: "{{ key_name }}"
        aws_ec2_vm_instance_type: "{{ fde_instance_type }}"
        aws_ec2_vm_image: "{{ fde_image }}"
        aws_ec2_vm_eth1_groups: "{{ mgmt_net_all.group_id }}"
        aws_ec2_vm_eth1_subnet: "{{ managementaz1.subnet.id }}"
        aws_ec2_vm_eth0_groups: "{{ cust_net_all.group_id }}"
        aws_ec2_vm_eth0_subnet: "{{ customeraz1.subnet.id }}"
        single_nic: false
        
    - name: Add FDE to fde group
      add_host:
        name: "{{ eth1.interface.private_ip_address }}"
        groups: fde
        
    - route53:
        state: present
        zone: "{{ vpc_shortname }}"
        record: "fde.{{ vpc_shortname }}"
        type: A
        private_zone: yes
        ttl: 300
        value: "{{ eth1.interface.private_ip_address }}"
        wait: yes
    
    - route53:
        state: present
        zone: "{{ vpc_longname }}"
        record: "fde.{{ vpc_longname }}"
        type: A
        private_zone: yes
        ttl: 300
        value: "{{ eth0.interface.private_ip_address }}"
        wait: yes
        
    - route53:
        state: present
        zone: in-addr.arpa
        hosted_zone_id: "{{ reverse_zone.zone_id }}"
        record: "{{ eth0.interface.private_ip_address | ipaddr('revdns') }}"
        type: PTR
        private_zone: yes
        ttl: 300
        value: "fde.{{ vpc_longname }}"
        wait: yes
        
    - name: Provision FDE-2 ec2 VM
      include_role:
        name: aws-ec2-vm
      vars:
        aws_ec2_vm_Name: FDE-2
        aws_ec2_vm_region: "{{ vpc_region }}"
        aws_ec2_vm_key_name: "{{ key_name }}"
        aws_ec2_vm_instance_type: "{{ fde_instance_type }}"
        aws_ec2_vm_image: "{{ fde_image }}"
        aws_ec2_vm_eth1_groups: "{{ mgmt_net_all.group_id }}"
        aws_ec2_vm_eth1_subnet: "{{ managementaz2.subnet.id }}"
        aws_ec2_vm_eth0_groups: "{{ cust_net_all.group_id }}"
        aws_ec2_vm_eth0_subnet: "{{ customeraz2.subnet.id }}"
        single_nic: false
      when: ha
      
    - name: Add FDE to fde-2 group
      add_host:
        name: "{{ eth1.interface.private_ip_address }}"
        groups: fde
      when: ha
       
    - name: Provision MidServerA ec2 VM
      include_role:
        name: aws-ec2-vm
      vars:
        aws_ec2_vm_Name: MidServerA
        aws_ec2_vm_region: "{{ vpc_region }}"
        aws_ec2_vm_key_name: "{{ key_name }}"
        aws_ec2_vm_instance_type: "{{ mid_instance_type }}"
        aws_ec2_vm_image: "{{ mid_image }}"
        aws_ec2_vm_eth0_groups: "{{ mgmt_net_all.group_id }}"
        aws_ec2_vm_eth0_subnet: "{{ managementaz1.subnet.id }}"
        single_nic: true
        
    - name: Add mid1 to mids group
      add_host:
        name: "{{ eth0.interface.private_ip_address }}"
        groups: mids
        
    - name: Provision MidServerB ec2 VM
      include_role:
        name: aws-ec2-vm
      vars:
        aws_ec2_vm_Name: MidServerB
        aws_ec2_vm_region: "{{ vpc_region }}"
        aws_ec2_vm_key_name: "{{ key_name }}"
        aws_ec2_vm_instance_type: "{{ mid_instance_type }}"
        aws_ec2_vm_image: "{{ mid_image }}"
        aws_ec2_vm_eth0_groups: "{{ mgmt_net_all.group_id }}"
        aws_ec2_vm_eth0_subnet: "{{ managementaz1.subnet.id }}"
        single_nic: true
        
    - name: Add mid2 to mids group
      add_host:
        name: "{{ eth0.interface.private_ip_address }}"
        groups: mids

    - name: Provision BUaaS-Networker-Server
      include_role:
        name: aws-ec2-vm
      vars:
        aws_ec2_vm_Name: BUaaS-Networker-Server
        aws_ec2_vm_region: "{{ vpc_region }}"
        aws_ec2_vm_key_name: "{{ key_name }}"
        aws_ec2_vm_instance_type: "{{ buaas_nwr_srv_instance_type }}"
        aws_ec2_vm_image: "{{ buaas_nwr_srv_image }}"
        aws_ec2_vm_eth0_groups: "{{ mgmt_net_all.group_id }}"
        aws_ec2_vm_eth0_subnet: "{{ managementaz1.subnet.id }}"
        single_nic: true
      when: buaas
        
    - route53:
        state: present
        zone: "{{ vpc_shortname }}"
        record: "nwr-srv.{{ vpc_shortname }}"
        type: A
        private_zone: yes
        ttl: 300
        value: "{{ eth0.interface.private_ip_address }}"
        wait: yes
      when: buaas
        
    - route53:
        state: present
        zone: in-addr.arpa
        hosted_zone_id: "{{ reverse_zone.zone_id }}"
        record: "{{ eth0.interface.private_ip_address | ipaddr('revdns') }}"
        type: PTR
        private_zone: yes
        ttl: 300
        value: "nwr-srv.{{ vpc_shortname }}"
        wait: yes
      when: buaas
        
    - name: Provision BUaaS-Networker-Console
      include_role:
        name: aws-ec2-vm
      vars:
        aws_ec2_vm_Name: BUaaS-Networker-Console
        aws_ec2_vm_region: "{{ vpc_region }}"
        aws_ec2_vm_key_name: "{{ key_name }}"
        aws_ec2_vm_instance_type: "{{ buaas_nwr_con_instance_type }}"
        aws_ec2_vm_image: "{{ buaas_nwr_con_image }}"
        aws_ec2_vm_eth0_groups: "{{ mgmt_net_all.group_id }}"
        aws_ec2_vm_eth0_subnet: "{{ managementaz1.subnet.id }}"
        single_nic: true
      when: buaas
        
    - route53:
        state: present
        zone: "{{ vpc_shortname }}"
        record: "nwr-con.{{ vpc_shortname }}"
        type: A
        private_zone: yes
        ttl: 300
        value: "{{ eth0.interface.private_ip_address }}"
        wait: yes
      when: buaas
        
    - route53:
        state: present
        zone: in-addr.arpa
        hosted_zone_id: "{{ reverse_zone.zone_id }}"
        record: "{{ eth0.interface.private_ip_address | ipaddr('revdns') }}"
        type: PTR
        private_zone: yes
        ttl: 300
        value: "nwr-con.{{ vpc_shortname }}"
        wait: yes
      when: buaas
        
    - name: Provision BUaaS-Cloudboost-Server
      include_role:
        name: aws-ec2-vm
      vars:
        aws_ec2_vm_Name: BUaaS-Cloudboost-Server
        aws_ec2_vm_region: "{{ vpc_region }}"
        aws_ec2_vm_key_name: "{{ key_name }}"
        aws_ec2_vm_instance_type: "{{ buaas_cb_instance_type }}"
        aws_ec2_vm_image: "{{ buaas_cb_image }}"
        aws_ec2_vm_eth0_groups: "{{ mgmt_net_all.group_id }}"
        aws_ec2_vm_eth0_subnet: "{{ managementaz1.subnet.id }}"
        single_nic: true
      when: buaas
        
    - route53:
        state: present
        zone: "{{ vpc_shortname }}"
        record: "nwr-cb.{{ vpc_shortname }}"
        type: A
        private_zone: yes
        ttl: 300
        value: "{{ eth0.interface.private_ip_address }}"
        wait: yes
      when: buaas
        
    - route53:
        state: present
        zone: in-addr.arpa
        hosted_zone_id: "{{ reverse_zone.zone_id }}"
        record: "{{ eth0.interface.private_ip_address | ipaddr('revdns') }}"
        type: PTR
        private_zone: yes
        ttl: 300
        value: "nwr-cb.{{ vpc_shortname }}"
        wait: yes
      when: buaas

    - name: Provision SAP Router ec2 VM
      include_role:
        name: aws-ec2-vm
      vars:
        aws_ec2_vm_Name: SAPRouter
        aws_ec2_vm_region: "{{ vpc_region }}"
        aws_ec2_vm_key_name: "{{ key_name }}"
        aws_ec2_vm_instance_type: "{{ proxy_instance_type }}"
        aws_ec2_vm_image: "{{ proxy_image }}"
        aws_ec2_vm_eth1_groups: "{{ mgmt_net_all.group_id }}"
        aws_ec2_vm_eth1_subnet: "{{ managementaz1.subnet.id }}"
        aws_ec2_vm_eth0_groups: "{{ pub_net_all.group_id }}"
        aws_ec2_vm_eth0_subnet: "{{ publicaz1.subnet.id }}"
        single_nic: false
        
    - name: Add saprouter to saprouter group
      add_host:
        name: "{{ eth1.interface.private_ip_address }}"
        groups: saprouter
        
    - route53:
        state: present
        zone: "{{ vpc_shortname }}"
        record: "proxy.{{ vpc_shortname }}"
        type: A
        private_zone: yes
        ttl: 300
        value: "{{ eth1.interface.private_ip_address }}"
        wait: yes
    
    - route53:
        state: present
        zone: "{{ vpc_longname }}"
        record: "proxy.{{ vpc_longname }}"
        type: A
        private_zone: yes
        ttl: 300
        value: "{{ eth0.interface.private_ip_address }}"
        wait: yes
        
    - route53:
        state: present
        zone: in-addr.arpa
        hosted_zone_id: "{{ reverse_zone.zone_id }}"
        record: "{{ eth0.interface.private_ip_address | ipaddr('revdns') }}"
        type: PTR
        private_zone: yes
        ttl: 300
        value: "proxy.{{ vpc_longname }}"
        wait: yes
        
    - name: Provision SAP-2 Router ec2 VM
      include_role:
        name: aws-ec2-vm
      vars:
        aws_ec2_vm_Name: SAPRouter-2
        aws_ec2_vm_region: "{{ vpc_region }}"
        aws_ec2_vm_key_name: "{{ key_name }}"
        aws_ec2_vm_instance_type: "{{ proxy_instance_type }}"
        aws_ec2_vm_image: "{{ proxy_image }}"
        aws_ec2_vm_eth1_groups: "{{ mgmt_net_all.group_id }}"
        aws_ec2_vm_eth1_subnet: "{{ managementaz2.subnet.id }}"
        aws_ec2_vm_eth0_groups: "{{ pub_net_all.group_id }}"
        aws_ec2_vm_eth0_subnet: "{{ publicaz2.subnet.id }}"
        single_nic: false
      when: ha
      
    - name: Add saprouter2 to saprouter group
      add_host:
        name: "{{ eth1.interface.private_ip_address }}"
        groups: saprouter
      when: ha


- name: Create DR Infrastructure
  hosts: localhost
  tasks:
    - name: Create VPC, Subnets, NAT Gateways, Route Tables, Security Groups and Route53 Zones
      include_role:
        name: aws-customer-infrastructure
      vars:
        aws_customer_vpc_cidr: "{{ dr_vpc_cidr }}"
        aws_customer_vpc_env_name: "{{ dr_vpc_env_name }}"
        aws_customer_vpc_region: "{{ dr_vpc_region }}"
        publicaz1_cidr: "{{ dr_pubaz1_cidr }}"
        publicaz2_cidr: "{{ dr_pubaz2_cidr }}"
        publicaz3_cidr: "{{ dr_pubaz3_cidr }}"
        managementaz1_cidr: "{{ dr_manaz1_cidr }}"
        managementaz2_cidr: "{{ dr_manaz2_cidr }}"
        managementaz3_cidr: "{{ dr_manaz3_cidr }}"
        customeraz1_cidr: "{{ dr_custaz1_cidr }}"
        customeraz2_cidr: "{{ dr_custaz2_cidr }}"
        customeraz3_cidr: "{{ dr_custaz3_cidr }}"
        clusteraz1_cidr: "{{ dr_clustaz1_cidr }}"
        clusteraz2_cidr: "{{ dr_clustaz2_cidr }}"
        clusteraz3_cidr: "{{ dr_clustaz3_cidr }}"
        aws_customer_vpc_management_cidr: "{{ vpc_management_cidr }}"
        aws_customer_vpc_shortname: "{{ vpc_shortname }}"
        aws_customer_vpc_longname: "{{ vpc_longname }}"
        create_zone: false
        single_az: "{{ dr_single_availability_zone }}"
      when: dr_compartment
    - name: Set VPC ID for DR Peering
      set_fact:
        drvpcid: "{{ customer_network.vpc.id }}"
      when: dr_compartment
    - name: Set DR Management AZ1 Route Table ID for DR Peering
      set_fact:
        drmanaz1rt: "{{ managementaz1_route_table.route_table.route_table_id }}"
      when: dr_compartment
    - name: Set DR Management AZ2 Route Table ID for DR Peering
      set_fact:
        drmanaz2rt: "{{ managementaz2_route_table.route_table.route_table_id }}"
      when: dr_compartment and not dr_single_availability_zone
    - name: Set DR Management AZ3 Route Table ID for DR Peering
      set_fact:
        drmanaz3rt: "{{ managementaz3_route_table.route_table.route_table_id }}"
      when: dr_compartment and not dr_single_availability_zone


- name: Provision Component Machines
  hosts: localhost
  tasks:
    - name: Provision FDE ec2 VM
      include_role:
        name: aws-ec2-vm
      vars:
        aws_ec2_vm_Name: FDE-DR
        aws_ec2_vm_region: "{{ dr_vpc_region }}"
        aws_ec2_vm_key_name: "{{ key_name }}"
        aws_ec2_vm_instance_type: "{{ fde_instance_type }}"
        aws_ec2_vm_image: "{{ dr_fde_image }}"
        aws_ec2_vm_eth1_groups: "{{ mgmt_net_all.group_id }}"
        aws_ec2_vm_eth1_subnet: "{{ managementaz1.subnet.id }}"
        aws_ec2_vm_eth0_groups: "{{ cust_net_all.group_id }}"
        aws_ec2_vm_eth0_subnet: "{{ customeraz1.subnet.id }}"
        single_nic: false
      when: dr_compartment
      
    - name: Add dr fde to fde group
      add_host:
        name: "{{ eth1.interface.private_ip_address }}"
        groups: fde
      when: dr_compartment

    - route53:
        state: present
        zone: "{{ vpc_shortname }}"
        record: "fdedr.{{ vpc_shortname }}"
        type: A
        private_zone: yes
        ttl: 300
        value: "{{ eth1.interface.private_ip_address }}"
        wait: yes
      when: dr_compartment

    - route53:
        state: present
        zone: "{{ vpc_longname }}"
        record: "fdedr.{{ vpc_longname }}"
        type: A
        private_zone: yes
        ttl: 300
        value: "{{ eth0.interface.private_ip_address }}"
        wait: yes
      when: dr_compartment
        
    - route53:
        state: present
        zone: in-addr.arpa
        hosted_zone_id: "{{ rev_zone }}"
        record: "{{ eth0.interface.private_ip_address | ipaddr('revdns') }}"
        type: PTR
        private_zone: yes
        ttl: 300
        value: "fdedr.{{ vpc_longname }}"
        wait: yes
      when: dr_compartment
    
    - name: Provision FDE-2 ec2 VM
      include_role:
        name: aws-ec2-vm
      vars:
        aws_ec2_vm_Name: FDE-DR-2
        aws_ec2_vm_region: "{{ dr_vpc_region }}"
        aws_ec2_vm_key_name: "{{ key_name }}"
        aws_ec2_vm_instance_type: "{{ fde_instance_type }}"
        aws_ec2_vm_image: "{{ dr_fde_image }}"
        aws_ec2_vm_eth1_groups: "{{ mgmt_net_all.group_id }}"
        aws_ec2_vm_eth1_subnet: "{{ managementaz2.subnet.id }}"
        aws_ec2_vm_eth0_groups: "{{ cust_net_all.group_id }}"
        aws_ec2_vm_eth0_subnet: "{{ customeraz2.subnet.id }}"
        single_nic: false
      when: dr_ha
      
    - name: Add dr fde2 to fde group
      add_host:
        name: "{{ eth1.interface.private_ip_address }}"
        groups: fde
      when: dr_compartment and dr_ha
      
    - name: Provision MidServerA ec2 VM DR
      include_role:
        name: aws-ec2-vm
      vars:
        aws_ec2_vm_Name: MidServerA-DR
        aws_ec2_vm_region: "{{ dr_vpc_region }}"
        aws_ec2_vm_key_name: "{{ key_name }}"
        aws_ec2_vm_instance_type: "{{ mid_instance_type }}"
        aws_ec2_vm_image: "{{ dr_mid_image }}"
        aws_ec2_vm_eth0_groups: "{{ mgmt_net_all.group_id }}"
        aws_ec2_vm_eth0_subnet: "{{ managementaz1.subnet.id }}"
        single_nic: true
      when: dr_compartment
      
    - name: Add dr mid1 to mids group
      add_host:
        name: "{{ eth0.interface.private_ip_address }}"
        groups: mids
      when: dr_compartment
        
    - name: Provision MidServerB ec2 VM DR
      include_role:
        name: aws-ec2-vm
      vars:
        aws_ec2_vm_Name: MidServerB-DR
        aws_ec2_vm_region: "{{ dr_vpc_region }}"
        aws_ec2_vm_key_name: "{{ key_name }}"
        aws_ec2_vm_instance_type: "{{ mid_instance_type }}"
        aws_ec2_vm_image: "{{ dr_mid_image }}"
        aws_ec2_vm_eth0_groups: "{{ mgmt_net_all.group_id }}"
        aws_ec2_vm_eth0_subnet: "{{ managementaz1.subnet.id }}"
        single_nic: true
      when: dr_compartment
      
    - name: Add dr mid2 to mids group
      add_host:
        name: "{{ eth0.interface.private_ip_address }}"
        groups: mids
      when: dr_compartment

    - name: Provision SAP Router ec2 VM
      include_role:
        name: aws-ec2-vm
      vars:
        aws_ec2_vm_Name: SAPRouter-DR
        aws_ec2_vm_region: "{{ dr_vpc_region }}"
        aws_ec2_vm_key_name: "{{ key_name }}"
        aws_ec2_vm_instance_type: "{{ proxy_instance_type }}"
        aws_ec2_vm_image: "{{ dr_proxy_image }}"
        aws_ec2_vm_eth1_groups: "{{ mgmt_net_all.group_id }}"
        aws_ec2_vm_eth1_subnet: "{{ managementaz1.subnet.id }}"
        aws_ec2_vm_eth0_groups: "{{ pub_net_all.group_id }}"
        aws_ec2_vm_eth0_subnet: "{{ publicaz1.subnet.id }}"
        single_nic: false
      when: dr_compartment
      
    - name: Add dr saprouter to saprouter group
      add_host:
        name: "{{ eth1.interface.private_ip_address }}"
        groups: saprouter
      when: dr_compartment

    - route53:
        state: present
        zone: "{{ vpc_shortname }}"
        record: "proxydr.{{ vpc_shortname }}"
        type: A
        private_zone: yes
        ttl: 300
        value: "{{ eth1.interface.private_ip_address }}"
        wait: yes
      when: dr_compartment
    
    - route53:
        state: present
        zone: "{{ vpc_longname }}"
        record: "proxydr.{{ vpc_longname }}"
        type: A
        private_zone: yes
        ttl: 300
        value: "{{ eth0.interface.private_ip_address }}"
        wait: yes
      when: dr_compartment
        
    - route53:
        state: present
        zone: in-addr.arpa
        hosted_zone_id: "{{ rev_zone }}"
        record: "{{ eth0.interface.private_ip_address | ipaddr('revdns') }}"
        type: PTR
        private_zone: yes
        ttl: 300
        value: "proxydr.{{ vpc_longname }}"
        wait: yes
      when: dr_compartment
      
    - name: Provision SAP Router ec2 VM
      include_role:
        name: aws-ec2-vm
      vars:
        aws_ec2_vm_Name: SAPRouter-DR
        aws_ec2_vm_region: "{{ dr_vpc_region }}"
        aws_ec2_vm_key_name: "{{ key_name }}"
        aws_ec2_vm_instance_type: "{{ proxy_instance_type }}"
        aws_ec2_vm_image: "{{ dr_proxy_image }}"
        aws_ec2_vm_eth1_groups: "{{ mgmt_net_all.group_id }}"
        aws_ec2_vm_eth1_subnet: "{{ managementaz2.subnet.id }}"
        aws_ec2_vm_eth0_groups: "{{ pub_net_all.group_id }}"
        aws_ec2_vm_eth0_subnet: "{{ publicaz2.subnet.id }}"
        single_nic: false
      when: dr_ha
      
    - name: Add dr saprouter2 to saprouter group
      add_host:
        name: "{{ eth1.interface.private_ip_address }}"
        groups: saprouter
      when: dr_compartment and dr_ha
      
    - name: Peer VPCs
      include_role:
        name: peer
      vars:
        region1: "{{ vpc_region }}"
        vpc1: "{{ vpcid }}"
        region2: "{{ dr_vpc_region }}"
        vpc2: "{{ drvpcid }}"
        peer_name: "DR Peering"
      when: dr_compartment

    - name: Update Route Table Management AZ1
      ec2_vpc_route_table:
        vpc_id: "{{ vpcid }}"
        region: "{{ vpc_region }}"
        route_table_id: "{{ manaz1rt }}"
        tags:
          Name: Management AZ1
        routes:
          - dest: "{{ dr_manaz1_cidr }}"
            vpc_peering_connection_id: "{{ vpc_peer.peering_id }}"
      when: dr_compartment
      
    - name: Update Route Table Management AZ2
      ec2_vpc_route_table:
        vpc_id: "{{ vpcid }}"
        region: "{{ vpc_region }}"
        route_table_id: "{{ manaz2rt }}"
        tags:
          Name: Management AZ2
        routes:
          - dest: "{{ dr_manaz2_cidr }}"
            vpc_peering_connection_id: "{{ vpc_peer.peering_id }}"
      when: dr_compartment and not single_availability_zone
      
    - name: Update Route Table Management AZ3
      ec2_vpc_route_table:
        vpc_id: "{{ vpcid }}"
        region: "{{ vpc_region }}"
        route_table_id: "{{ manaz3rt }}"
        tags:
          Name: Management AZ3
        routes:
          - dest: "{{ dr_manaz3_cidr }}"
            vpc_peering_connection_id: "{{ vpc_peer.peering_id }}"
      when: dr_compartment and not single_availability_zone
      
    - name: Update DR Route Table Management AZ1
      ec2_vpc_route_table:
        vpc_id: "{{ drvpcid }}"
        region: "{{ dr_vpc_region }}"
        route_table_id: "{{ drmanaz1rt }}"
        tags:
          Name: Management AZ1
        routes:
          - dest: "{{ manaz1_cidr }}"
            vpc_peering_connection_id: "{{ vpc_peer.peering_id }}"
      when: dr_compartment
      
    - name: Update DR Route Table Management AZ2
      ec2_vpc_route_table:
        vpc_id: "{{ drvpcid }}"
        region: "{{ dr_vpc_region }}"
        route_table_id: "{{ drmanaz2rt }}"
        tags:
          Name: Management AZ2
        routes:
          - dest: "{{ manaz2_cidr }}"
            vpc_peering_connection_id: "{{ vpc_peer.peering_id }}"
      when: dr_compartment and not dr_single_availability_zone
      
    - name: Update DR Route Table Management AZ3
      ec2_vpc_route_table:
        vpc_id: "{{ drvpcid }}"
        region: "{{ dr_vpc_region }}"
        route_table_id: "{{ drmanaz3rt }}"
        tags:
          Name: Management AZ3
        routes:
          - dest: "{{ manaz3_cidr }}"
            vpc_peering_connection_id: "{{ vpc_peer.peering_id }}"
      when: dr_compartment and not dr_single_availability_zone
      
    - ec2_group:
        name: mgmt-net-all
        description: Every AWS interface in the VPCs AZ1 2 3 management networks must be assigned to this security group
        vpc_id: "{{ drvpcid }}"
        region: "{{ dr_vpc_region }}"
        rules:
          - proto: -1
            ports: 0
            cidr_ip: 172.64.0.0/12
      register: mgmt_net_all_dr
      when: dr_compartment
      
- name: CSR Spoke Creation
  hosts: localhost
  tasks:
    - include_role:
        name: csr_automation
      vars:
        customer_accout: "{{ customer_account }}"
        vpc_name: "{{ vpc_env_name }}"
        vgw_owner: "{{ vgw_owner }}"
        region: "{{ vpc_region }}"
        key_arn: "{{ key_arn }}"
        management_access_key: "{{ management_access_key }}"
        management_secret_key: "{{ management_secret_key }}"
        customer_access_key: "{{ customer_access_key }}"
        customer_secret_key: "{{ customer_secret_key }}"
        bucket_name: "{{ bucket_name }}"
        stack_name: "{{ stack_name }}"
        vgw_name: "{{ vgw_name }}"
        key_alias: "{{ key_alias }}"

- name: Configure FDE Server
  hosts: FDE
  tasks:
    - name: Call role
      include_role:
        name: fde
      vars:
        #The customer and management subnet CIDR ranges should cover multiple AZ's if deploying on AWS, for example 172.17.104.0/21 would cover multiple AZs
        customer_subnet_cidr: "{{ customer_range }}"
        customer_management_subnet_cidr: "{{ management_range }}"
        #This is the IP of the LaMa instance for the associated management compartment
        lama_ip: "10.4.0.41"
        #Customer Lan (all AZ's) of customer
        customer_lan: "172.16.0.0/12"
        #Customer Lan (all AZ's) of customer
        management_lan: "172.17.0.0/12"
        #IPs of Dev/Test DNS Forwarders
        dns_ip_dev: "10.4.0.5"
        dns_ip_test: "10.2.0.5"
        #DNS Zones for mangement, customer and reverse DNS
        management_zone: "{{ vpc_shortname }}"
        customer_zone: "{{ vpc_longname }}"
        reverse_zone: "in-addr.arpa"
        #Forwarder IPs for each zone, for Azure these are taken from the nameserver addresses for each zone. For AWS it is by default the x.x.x.2 of the CIDR, e.g. 172.17.104.2
        management_forwarders: "80.20.3.1; 6.80.232.2; 87.56.3.2;"
        customer_forwarders: "32.32.32.0; 6.80.232.2; 89.76.23.1;"
        reverse_forwarders: "40.3.32.1; 80.20.3.1; 6.80.232.2;"
        #Forwarder IP, if Azure then 168.63.129.16, if AWS then first IP in management range, e.g. 172.17.0.2
        forwarder_ip: "168.63.129.16"
        #FDE customer domain is the customer domain
        fde_customer_domain: "{{ vpc_longname }}"
        #Management IP of the FDE itself
        fde_ip: "{{ ansible_default_ipv4.address }}"

- name: Configure SAP Router Server
  hosts: SAPRouter
  tasks:
    - name: Call SAP Router Role
      include_role:
        name: saprouter
      vars:
       management_subnet_cidr: 10.6.0.0/24
